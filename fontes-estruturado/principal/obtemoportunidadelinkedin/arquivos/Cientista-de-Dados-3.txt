[Oportunidade 1]
Oportunidade: Data Developer (Engenharia de Dados) SÃªnior/Especialista

Sobre a vaga
Estamos com uma oportunidade para um(a) Data Developer SÃªnior ou Especialista (Engenharia de Dados). Como parte do time de produtos de dados, sua missÃ£o Ã© usar seus conhecimentos, habilidades para explorar problemas, desenhar, desenvolver produtos impactantes, entregar observando governanÃ§a, seguranÃ§a e performance, em um ambiente colaborativo e de inovaÃ§Ã£o.

Acreditamos que a engenharia de dados Ã© uma disciplina essencial para este produto, sendo responsÃ¡vel pela arquitetura e tecnologias para movimentar e organizar grandes volumes de dados, observando governanÃ§a, seguranÃ§a e performance.

ğŸ§‘â€ğŸ¦½Todas as nossas vagas estÃ£o disponÃ­veis para pessoas com deficiÃªncia! Que tal se juntar ao nosso time e embarcar nessa jornada com a gente?

Responsabilidades:
Participar das conversas sobre o produto e parear com Group Product Manager e Product Managers, entendendo e garantindo a entrega de valor;
Criar dashboards e visualizaÃ§Ãµes de dados que apoiem a tomada de decisÃ£o;
Desenhar a arquitetura e avaliar as tecnologias disponÃ­veis para resolver o problema certo;
Combinar a arquitetura e tecnologia para desenvolver e entregar componentes reutilizÃ¡veis como conectores, APIs, SDKs, CLIs;
Testar e automatizar tudo que for possÃ­vel;
Validar e adaptar os componentes de acordo com os feedbacks dos usuÃ¡rios;
Colaborar com a qualidade e inovaÃ§Ã£o tecnolÃ³gica do produto e ambiente de trabalho.
Conhecimentos e Habilidades
Facilidade para aprender novas tecnologias e se adaptar Ã s mudanÃ§as;
Git Workflows, CI/CD e automaÃ§Ã£o de processos;
Infra as a Code - OpenTofu/Terraform;
Facilidade de comunicaÃ§Ã£o e colaboraÃ§Ã£o com outras pessoas;
Conhecimento e habilidade em alguma linguagem de programaÃ§Ã£o e consulta, preferencialmente Python e/ou Java e SQL;
Conhecimento e habilidade em alguma tecnologia de processamento distribuÃ­do, preferencialmente Spark;
Conhecimento e habilidade em alguma nuvem, incluindo serviÃ§os de computaÃ§Ã£o, armazenamento, bancos de dados e Analytics em AWS;
Conhecimento e habilidade em bancos de dados SQL, NoSQL e serviÃ§os de streaming distribuÃ­dos, por exemplo: PostgreSQL, Cassandra e Kafka;
Conhecimento sobre arquiteturas de Big Data, por exemplo: Data Warehouse, Data Lake, Lambda, Kappa, Data Mesh;
Conhecimento sobre modelagem e cargas de trabalho de dados, incluindo modelagem normalizada, multi-dimensional, e cargas de trabalho OLTP e OLAP;
VivÃªncia com grande volume de dados;

Requisitos e QualificaÃ§Ãµes:
Git Workflows, CI/CD e automaÃ§Ã£o de processos;
Infra as a Code - OpenTofu/Terraform;
Conhecimento e habilidade em alguma linguagem de programaÃ§Ã£o e consulta, preferencialmente Python e/ou Java e SQL;
Conhecimento e habilidade em alguma tecnologia de processamento distribuÃ­do, preferencialmente Spark;
Conhecimento e habilidade em alguma nuvem, incluindo serviÃ§os de computaÃ§Ã£o, armazenamento, bancos de dados e Analytics em AWS;
Conhecimento e habilidade em bancos de dados SQL, NoSQL e serviÃ§os de streaming distribuÃ­dos, por exemplo: PostgreSQL, Cassandra e Kafka;
Conhecimento sobre arquiteturas de Big Data, por exemplo: Data Warehouse, Data Lake, Lambda, Kappa, Data Mesh;
Conhecimento sobre modelagem e cargas de trabalho de dados, incluindo modelagem normalizada, multi-dimensional, e cargas de trabalho OLTP e OLAP;
VivÃªncia com grande volume de dados;

O que te tornaria um especialista para essa vaga:
Conhecimento avanÃ§ado em alguma tecnologia de processamento distribuÃ­do, preferencialmente Spark, e/ou bancos de dados SQL e/ou NoSQL, preferencialmente Oracle, PostgreSQL e/ou DynamoDB;
ExperiÃªncia com ambientes de Big Data em produÃ§Ã£o, incluindo o desenho da arquitetura, provisionamento de infraestrutura, desenvolvimento de integraÃ§Ã£o de dados (pipelines, workflows), monitoramento de performance e custos;

O que seria muito legal se vocÃª tivesse:
ExperiÃªncia com produtos em especial ERP;
Conhecimento em AWS: Athena, S3, Lambda, IAM;
Conhecimento em Cloud em especial AWS;
Conhecimento em em alguma plataforma como DataBricks, SnowFlake ou DataIku.
Ter participado em construÃ§Ã£o de produtos de dados e inteligÃªncia artificial

O modelo de trabalho varia conforme a localizaÃ§Ã£o: presencial para quem estÃ¡ em UberlÃ¢ndia/MG, hÃ­brido (3x por semana no escritÃ³rio) para SÃ£o Paulo/SP e remoto para as demais regiÃµes.

Se vocÃª deseja crescer, encarar novos desafios e fazer parte de um time que estÃ¡ construindo algo grande, seu lugar Ã© aqui! Topa o desafio?

BenefÃ­cios que vÃ£o alÃ©m da Jornada Sankher
Na Sankhya, valorizamos a individualidade e oferecemos benefÃ­cios que promovem liberdade, equilÃ­brio e bem-estar em todas as Ã¡reas da vida.

ğŸ’µ ParticipaÃ§Ã£o nos Resultados (PPR)
ğŸ¥— Vale AlimentaÃ§Ã£o/RefeiÃ§Ã£o iFood
ğŸ¤° LicenÃ§a Maternidade e Paternidade Estendida
ğŸ‘¶ AuxÃ­lio Creche
ğŸ©º Plano de saÃºde
ğŸ˜ Plano odontolÃ³gico
ğŸ‰ Day OFF no AniversÃ¡rio
ğŸ’µ EmprÃ©stimo Consignado
ğŸ‹ï¸ AuxÃ­lio vida saudÃ¡vel
ğŸ’š Seguro de Vida
ğŸš Vale Transporte
ğŸ’» Equipamentos Fornecidos pela Empresa
ğŸŒ AuxÃ­lio Idiomas
ğŸ“œ AuxÃ­lio GraduaÃ§Ã£o, PÃ³s-GraduaÃ§Ã£o, AuxÃ­lio CertificaÃ§Ãµes, Universidade Corporativa Sankhya

ğŸ” Na Sankhya, sua jornada de crescimento nunca para. ğŸš€ğŸ’š

ğŸ¯ Plano de Performance e Desenvolvimento Individual: Plano personalizado para seu crescimento profissional.
ğŸ“Œ Touchpoints de EvoluÃ§Ã£o com a LideranÃ§a: Encontros regulares com lÃ­deres para discutir seu progresso e desenvolvimento.
-----------------------------------------------------------------------------------
[Oportunidade 2]
Oportunidade: Engenheiro de dados

Sobre a vaga
Na Stefanini, acreditamos no poder da colaboraÃ§Ã£o. Co-criamos soluÃ§Ãµes inovadoras em parceria com nossos clientes, combinando tecnologia de ponta, inteligÃªncia artificial e a criatividade humana. Estamos na vanguarda da resoluÃ§Ã£o de problemas de negÃ³cios, proporcionando impacto real em escala global.

Ao se juntar Ã  Stefanini, vocÃª se torna parte de uma jornada global de transformaÃ§Ã£o. Estamos empenhados em criar impacto positivo nÃ£o apenas nos negÃ³cios, mas tambÃ©m na vida de nossos colaboradores. Se vocÃª procura uma oportunidade de crescimento profissional em uma empresa que valoriza inovaÃ§Ã£o, respeito, autonomia e parceria, vocÃª encontra aqui!

Junte-se a nÃ³s e seja parte da mudanÃ§a!

Buscamos um Engenheiro de dados SÃªnior com sÃ³lida experiÃªncia em Python para liderar o desenvolvimento e implementaÃ§Ã£o de um Master Data Management (MDM) de Pacientes. O profissional irÃ¡ trabalhar na modelagem de dados, especificaÃ§Ã£o de regras de negÃ³cios e implementaÃ§Ã£o dessas regras e tabelas no ambiente Databricks, unificando dados de pacientes provenientes de mÃºltiplos sistemas de origem.


Responsabilidades e atribuiÃ§Ãµes
Desenvolver e implementar a arquitetura de modelagem de dados do MDM de Pacientes
Especificar e documentar regras de negÃ³cios para unificaÃ§Ã£o e tratamento de dados de pacientes
Implementar pipelines de processamento de dados no Databricks
Desenvolver lÃ³gicas para matching, deduplicate e golden record de pacientes
Estabelecer fluxos de qualidade de dados e validaÃ§Ã£o
Criar e manter tabelas integradas seguindo as regras de negÃ³cios estabelecidas
Implementar rotinas de atualizaÃ§Ã£o e sincronizaÃ§Ã£o de dados
Participar de code reviews e mentoria tÃ©cnica da equipe
Colaborar com stakeholders de negÃ³cios para refinar regras e requisitos

Requisitos essenciais:
ExperiÃªncia avanÃ§ada com Python
SÃ³lidos conhecimentos em:
Databricks e Delta Lake
PySpark para processamento de dados em larga escala
SQL e modelagem de dados
ETL/ELT e pipelines de dados

ExperiÃªncia com Master Data Management (MDM) ou projetos similares de integraÃ§Ã£o de dados
Conhecimento em tÃ©cnicas de matching, fuzzy matching e deduplicaÃ§Ã£o de registros
ExperiÃªncia com implementaÃ§Ã£o de regras de negÃ³cios complexas em cÃ³digo
DomÃ­nio de versionamento Git e metodologias Ã¡geis
ExperiÃªncia com boas prÃ¡ticas de desenvolvimento (testes unitÃ¡rios, documentaÃ§Ã£o)

Diferenciais:
ExperiÃªncia prÃ©via com MDM na Ã¡rea de saÃºde
Conhecimento em FHIR ou outros padrÃµes de dados de saÃºde
ExperiÃªncia com Great Expectations para qualidade de dados
Conhecimento em frameworks de governanÃ§a de dados
ExperiÃªncia com mensageria (Kafka, Event Hubs)
Familiaridade com ferramentas de CDC (Change Data Capture)
Conhecimento em observabilidade (Databricks SQL Analytics, Grafana)
ExperiÃªncia com APIs RESTful para exposiÃ§Ã£o de dados


BenefÃ­cios:

ğŸ› Vale AlimentaÃ§Ã£o ou Vale RefeiÃ§Ã£o;
ğŸ‘¨ğŸ¼â€ğŸ“ Desconto em cursos, universidades e instituiÃ§Ãµes de idiomas;
ğŸ“š Academia Stefanini - plataforma com cursos online, gratuitos, atualizados e com certificado;
ğŸ—£ Mentoring;
ğŸ« AuxÃ­lio Creche;
ğŸ’‰ Clube de vantagens para consultas e exames;
ğŸ¥ AssistÃªncia MÃ©dica;
ğŸ¦·AssistÃªncia OdontolÃ³gica;
ğŸ’° Clube de vantagens e descontos nos melhores estabelecimentos;
ğŸ›« Clube de viagens;
ğŸ¶ ConvÃªnio para Pet;
e muito mais...
-----------------------------------------------------------------------------------
[Oportunidade 3]
Oportunidade: Engenheiro(a) de Dados | Remoto

Sobre a vaga
SOBRE A CAPCO 

A Capco Ã© uma consultoria global de tecnologia e gestÃ£o especializada na transformaÃ§Ã£o digital, oferecendo soluÃ§Ãµes inovadoras e orientadas por dados para um portfÃ³lio crescente de mais de 100 clientes globais, entre eles bancos, pagamentos, mercados de capitais, gestÃ£o de patrimÃ´nio e ativos, seguros e setor de energia.

Nos destacamos pela abordagem personalizada, focada na construÃ§Ã£o de parcerias estratÃ©gicas de longo prazo e na aceleraÃ§Ã£o de iniciativas digitais. Nossa expertise ganha vida por meio dos Innovation Labs e da cultura premiada #BeYourselfAtWork, que valoriza a diversidade e o talento.

Temos oportunidades em formato presencial, hÃ­brido e remoto, com vagas disponÃ­veis em diversas localidades no Brasil. Com presenÃ§a global nos principais centros financeiros - temos 33 escritÃ³rios nas AmÃ©ricas, Europa e Ãsia-PacÃ­fico - estamos comprometidos em oferecer soluÃ§Ãµes prÃ¡ticas e integradas, promovendo colaboraÃ§Ã£o e confianÃ§a em cada projeto. Se criatividade e inovaÃ§Ã£o sÃ£o sua paixÃ£o, a Capco Ã© ideal para vocÃª. Vamos te apoiar e ajudar a acelerar sua carreira!

Sobre a PosiÃ§Ã£o

Estamos em busca de um(a) Engenheiro(a) de Dados com experiÃªncia em ambientes on-premise e cloud, para atuar na migraÃ§Ã£o e modernizaÃ§Ã£o da camada de dados . A atuaÃ§Ã£o envolve o desenvolvimento de pipelines, transformaÃ§Ã£o de dados e integraÃ§Ã£o com plataformas modernas como Azure Data Factory e Databricks, alÃ©m de sÃ³lidos conhecimentos de ETL e Informatica Power Center.

Responsabilidades

Desenvolver pipelines de ingestÃ£o e transformaÃ§Ã£o de dados para migraÃ§Ã£o de sistemas legados (Oracle, DB2, PowerCenter) para o ambiente em nuvem (Azure). 
Mapear estruturas de dados, tabelas e processos existentes, implementando regras de negÃ³cio na nova arquitetura.
Criar e manter estruturas eficientes de armazenamento em Delta Lake.
Assegurar qualidade, integridade e rastreabilidade dos dados com aplicaÃ§Ã£o de regras de validaÃ§Ã£o e controle.
Trabalhar em conjunto com arquitetos e analistas de negÃ³cio para garantir entregas alinhadas Ã s necessidades funcionais.
Documentar fluxos, processos e lÃ³gicas de transformaÃ§Ã£o de dados.
Monitorar e otimizar performance de pipelines e jobs em produÃ§Ã£o.

Requisitos Essenciais

ExperiÃªncia com ferramentas de integraÃ§Ã£o de dados (Azure Data Factory, Databricks, PowerCenter).
SÃ³lidos conhecimentos de SQL avanÃ§ado e linguagem Python.
ExperiÃªncia com bancos de dados relacionais (Oracle e DB2).
Familiaridade com arquitetura de dados moderna: Delta Lake, medallion architecture (bronze, silver, gold).
ExperiÃªncia em projetos de migraÃ§Ã£o e integraÃ§Ã£o de dados corporativos.
Conhecimento em controles de qualidade de dados e versionamento de pipelines.

Requisitos DesejÃ¡veis

ExperiÃªncia com dados no segmento Seguros e SaÃºde.
NoÃ§Ãµes de Machine Learning com Databricks MLLib.
Familiaridade com ferramentas de orquestraÃ§Ã£o e observabilidade.
Conhecimentos de modelagem dimensional e boas prÃ¡ticas de DW/BI.

Por Que Capco

Na Capco, promovemos uma cultura inclusiva. Valorizamos a diversidade em todas as suas expressÃµes. Pensamos, em conjunto, sempre em aÃ§Ãµes diversas de inclusÃ£o e de responsabilidade social atravÃ©s de comitÃªs internos geridos pela nossa comunidade, como os grupo de Mulheres, Pessoas Com DeficiÃªncia, Pessoas Negras, LGBTQIAPN+, Parentalidade, GeraÃ§Ãµes, entre outros. Juntar-se Ã  Capco significa ingressar em uma organizaÃ§Ã£o comprometida com um ambiente de trabalho inclusivo onde vocÃª Ã© incentivado a #BeYourselfAtWork (Ser VocÃª Mesmo no Trabalho). Celebramos a individualidade e reconhecemos que a diversidade e a inclusÃ£o, em todas as formas, sÃ£o fundamentais para o sucesso. Acreditamos que todos trazem algo diferente, por isso adorarÃ­amos saber o que o torna diferente! 

Juntar-se Ã  Capco significa ingressar em uma organizaÃ§Ã£o comprometida com um ambiente de trabalho inclusivo onde vocÃª Ã© incentivado a #BeYourselfAtWork (Ser VocÃª Mesmo no Trabalho). Celebramos a individualidade e reconhecemos que a diversidade e a inclusÃ£o, em todas as formas, sÃ£o fundamentais para o sucesso. Acreditamos que todos trazem algo diferente, por isso adorarÃ­amos saber o que o torna diferente!

PrÃ³ximos Passos

O objetivo da Capco Ã© conduzir um processo flexÃ­vel e alinhado Ã s necessidades de cada oportunidade e talento.

Etapa 1: Entrevista comportamental.
Etapa 2: Entrevista tÃ©cnica.
Etapa 3: Conversa com time de Projeto/ Delivery.
Etapa 4: Conversa com cliente.
Etapa 5: Proposta ou feedback.

As etapas do nosso processo seletivo descritas sÃ£o essenciais para garantir uma avaliaÃ§Ã£o completa e assertiva. Contudo, elas podem ser ajustadas dependendo da senioridade do(a) candidato(a), da Ã¡rea de atuaÃ§Ã£o e do formato do projeto.
-----------------------------------------------------------------------------------
[Oportunidade 4]
Oportunidade: Engenheiro de Dados Pleno

Sobre a vaga
Sobre nÃ³s 

A XP Inc. Ã© uma das maiores instituiÃ§Ãµes financeiras independente do Brasil, dona das marcas XP, Rico, Clear, XP EducaÃ§Ã£o, InfoMoney, entre outras. Com mais de 4,6 milhÃµes de clientes ativos e um valor superior a R$ 1,1 trilhÃ£o de ativos sob custÃ³dia, hÃ¡ 23 anos vem transformando o mercado financeiro para melhorar a vida das pessoas.

Com uma cultura marcante guiada por quatro valores - Sonho Grande, EspÃ­rito Empreendedor, Foco no Cliente e Mente Aberta - a XP Inc. estÃ¡ sempre em busca dos melhores talentos que tem ambiÃ§Ã£o de fazer o impossÃ­vel.

ğŸš€ Sobre a Oportunidade

Essa oportunidade Ã© para a Ã¡rea de Dados e Analytics em PrevenÃ§Ã£o a Fraudes e Atendimento, que tem a missÃ£o de criar do comeÃ§o ao fim, produtos de dados que gerem valor e suportem decisÃµes de negÃ³cio. Esse Ã© um time apaixonado por dados, vocÃª pode se dar muito bem se gostar de Modelagem e Engenharia de Dados, SQL e Python.

Saiba mais sobre nosso dia a dia no Instagram e no LinkedIn.

Confira nossas avaliaÃ§Ãµes no Glassdoor.

ğŸ” O Que Procuramos

PrÃ©-requisitos Essenciais

Conhecimento avanÃ§ado em SQL; 
Conhecimento avanÃ§ado em Python; 
ExperiÃªncia com modelagem de dados e construÃ§Ã£o de pipelines de ETL; 
Conhecimento em ferramentas de Data Viz; 
RaciocÃ­nio lÃ³gico e perfil analÃ­tico; 
Residir em SÃ£o Paulo 

Diferenciais

Tiver conhecimento em PySpark; 
Tiver experiÃªncia com Databricks; 
Tiver conhecimento em Power BI e DAX; 
ExperiÃªncia com uso de IA generativa. 

ğŸ¯ Desafios e Impacto

Modelagem e Engenharia de Dados para criaÃ§Ã£o de DAGs de ETL, utilizando SQL e Python dentro da plataforma Databricks; 
Estudos para embasar decisÃµes de negÃ³cio; 
CriaÃ§Ã£o de Dashboards utilizando o Power BI; 
InteraÃ§Ã£o com Stakeholders. 

â³ Etapas do Processo

Triagem inicial: AnÃ¡lise do currÃ­culo para verificar a adequaÃ§Ã£o Ã s qualificaÃ§Ãµes e requisitos da vaga. 
Teste cognitivo: Teste de raciocÃ­nio lÃ³gico da Predictive Index.
Entrevista com a equipe de Recrutamento: DiscussÃ£o sobre as expectativas em relaÃ§Ã£o Ã  vaga e aos objetivos profissionais. 
Entrevista com a lideranÃ§a: Uma conversa para discutir sua visÃ£o e como vocÃª pode contribuir para a equipe e a empresa. 
Entrevista com colegas de trabalho: InteraÃ§Ã£o com futuros pares para avaliar a sinergia e o trabalho em equipe. 
Entrevista focada em cultura: ExploraÃ§Ã£o dos valores e princÃ­pios da empresa para garantir um bom encaixe cultural. 
Oferta: ApresentaÃ§Ã£o da proposta de trabalho, incluindo detalhes sobre remuneraÃ§Ã£o e benefÃ­cios. 

BenefÃ­cios:  

SaÃºde e Bem-estar

Plano de saÃºde sem coparticipaÃ§Ã£o (inclusive, para dependentes)
Plano odontolÃ³gico
Wellhub (Gympass)
Zenklub
Seguro de Vida
iFood BenefÃ­cios (VA e VR flexÃ­vel)
Vale Transporte
New Value (clube de benefÃ­cios)
LicenÃ§a parental: maternidade de 6 meses e paternidade de 20 dias.
AuxÃ­lio Creche

Vida Financeira

Fundos de Investimentos Exclusivos
Assessoria de Investimentos 
CartÃ£o XP Visa Infinite sem anuidade 
CrÃ©dito (consignado, home equity, CCB ImobiliÃ¡rio, etc.) 

Modelo de Trabalho Presencial FlexÃ­vel 

O nosso modelo de trabalho varia de acordo com a funÃ§Ã£o, podendo ser totalmente presencial para frentes de negÃ³cio e mais flexÃ­vel para outras equipes.

Seguimos um modelo com mais frequÃªncia presencial, mas sempre guiado por flexibilidade e autonomia com a responsabilidade da nossa cultura empreendedora.

Aqui na XP Inc., valorizamos as interaÃ§Ãµes pessoais e acreditamos no uso do escritÃ³rio como uma ferramenta para potencializar nossas relaÃ§Ãµes no trabalho.
-----------------------------------------------------------------------------------
[Oportunidade 5]
Oportunidade: Cientista de Dados / HÃ­brido - Rio de Janeiro/RJ

Sobre a vaga
REQUISITOS MANDATÃ“RIOS

EXPERIÃŠNCIA

ExperiÃªncia com anÃ¡lise e modelagem de dados aplicadas Ã  indÃºstria de Ã³leo e gÃ¡s AtuaÃ§Ã£o prÃ©via em empresas do setor energÃ©tico ou projetos envolvendo engenharia de dados e analytics VivÃªncia em projetos de otimizaÃ§Ã£o operacional, manutenÃ§Ã£o preditiva e monitoramento de ativos;
Habilidade com Linguagens de ProgramaÃ§Ã£o: Python, R, SQL Machine Learning & EstatÃ­stica: Modelagem preditiva, sÃ©ries temporais, aprendizado de mÃ¡quina Banco de Dados: PostgreSQL, SQL Server, NoSQL (MongoDB, Cassandra) Processamento;
Conhecimento com Engenharia de Dados: ETL, Apache Spark, Databricks;
Habilidade com Power BI
Habilidade com Cloud Computing: AWS, Azure, Google Cloud (foco na infraestrutura utilizada pela Petrobras) e Big Data: Hadoop, Kafka;
Conhecimento em ferramentas de DevOps e MLOps: Docker, Kubernetes, Git, CI/CD;
Capacidade analÃ­tica e visÃ£o estratÃ©gica para transformar dados em insights acionÃ¡veis ComunicaÃ§Ã£o clara para interagir com equipes multidisciplinares (engenharia, TI, negÃ³cios) Proatividade na resoluÃ§o de problemas operacionais e suporte Ã  tomada de decisÃ£o AdaptaÃ§Ã£o a ambientes regulados e metodologias Ã¡geis.

ESCOLARIDADE

GraduaÃ§Ã£o: Superior em Engenharia, CiÃªncia da ComputaÃ§Ã£o, EstatÃ­stica, MatemÃ¡tica, FÃ­sica, ou Ã¡reas correlatas. 
PÃ³s-graduaÃ§Ã£o: PÃ³s-graduaÃ§Ã£o ou MBA em CiÃªncia de Dados, InteligÃªncia Artificial ou Big Data (desejÃ¡vel).
CertificaÃ§Ã£o: Ao menos uma das certificaÃ§Ãµes a seguir (CertificaÃ§Ã£o PMI-ACP, CBPP, BPM ou Lean 6-Sigma (Black Belt) ou CertificaÃ§Ã£o PMP ou PMI-ACP, Professional Scrum Master (PSM), Team Kanban Practitioner (TKP), Lean 6-Sigma (Black Belt) ou CeritificaÃ§Ã£o Oficial SAFeÂ®
CertificaÃ§Ãµes (DesejÃ¡veis)

Microsoft Certified: Azure Data Scientist Associate AWS Certified Machine Learning â€“ Specialty Google Professional Data Engineer CertificaÃ§Ãµes em Big Data, Machine Learning e Analytics VisualizaÃ§Ã£o de Dados: Tableau, Grafana

ATRIBUIÃ‡Ã•ES

Atuar nos subeixos de conformidade, desenvolvimento de habilidades e competÃªncias, negÃ³cios, processos, projetos, cadeia de suprimentos e transformaÃ§Ã£o digital, realizando a coordenaÃ§Ã£o tÃ©cnica, anÃ¡lises crÃ­ticas, apoio estratÃ©gico, otimizaÃ§Ãµes, estudos tÃ©cnicos, conduÃ§Ã£o de trabalhos tÃ©cnicos especializados, desenvolvimento de soluÃ§Ãµes, melhoria dos processos e atividades, consultorias, identificaÃ§Ã£o de riscos e oportunidades. 

REQUISITOS DESEJÃVEIS

CertificaÃ§Ãµes em Microsoft Power Platform, Azure Solutions Architect e Automation Anywhere;
ExperiÃªncia em InteligÃªncia Artificial e Machine Learning para anÃ¡lise avanÃ§ada de dados;
Soft Skills: Habilidade para interpretar e explorar dados de forma estratÃ©gica;
Boa comunicaÃ§Ã£o para interagir com equipes tÃ©cnicas e de negÃ³cios;
Capacidade de trabalhar em ambientes dinÃ¢micos e de rÃ¡pida transformaÃ§Ã£o.

Sobre a CAPCO

Na Capco promovemos uma cultura inclusiva. Valorizamos a diversidade em todas as suas expressÃµes. 

Pensamos, em conjunto, sempre em aÃ§Ãµes diversas de inclusÃ£o e de responsabilidade social atravÃ©s de comitÃªs internos geridos pela nossa comunidade interna, como os grupo de Mulheres, Pessoas Com DeficiÃªncia, Pessoas Negras, LGBTQIAPN+, Parentalidade, GeraÃ§Ãµes, entre outros.

Nossas oportunidades sÃ£o trabalhadas para todos(as)!!!



PrÃ³ximos Passos

Se vocÃª estÃ¡ ansioso(a) para progredir sua carreira conosco, candidate-se e aguarde o contato de um de nossos recrutadores!
-----------------------------------------------------------------------------------
